{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e61dc7a0-2e12-4d72-bf92-c5d9fa36aa6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#tables = orders , customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f71acc0d-6127-4146-afc5-1262f35dda6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.readStream.format('cloudFiles')\\\n",
    "            .option('cloudFiles.format','json')\\\n",
    "            .option('cloudFiles.schemaLocation','dbfs:/FileStore/tables/orders/schema')\\\n",
    "            .option('header','true')\\\n",
    "            .option('multiline','true')\\\n",
    "            .option('escape','\"')\\\n",
    "            .option('quote','\"')\\\n",
    "            .schema(json_schema)\\\n",
    "            .load('/FileStore/tables/orders/orders')\n",
    "\n",
    "display(df.limit(5))\n",
    "\n",
    "\n",
    "\n",
    "#droping col name dump where there is json dump which is not relavant \n",
    "df.drop('dump')\n",
    "\n",
    "#primary key is cust_id and should not be null\n",
    "df.filter(df.cust_id.isNotNull())\n",
    "\n",
    "#ingestion timing \n",
    "df.withColumn('current_ts',current_timestamp())\n",
    "\n",
    "#add file path name \n",
    "df.withColumn('file_name' , '_metadata.file_path')\n",
    "\n",
    "\n",
    "#write to delta\n",
    "df.writeStream.format('delta')\\\n",
    "      .partitionBy('order_date')\\\n",
    "      .outputMode('append')\\\n",
    "      .option('checkpointLocation','dbfs:/FileStore/tables/orders/checkpoint')\\\n",
    "      .table('orders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99e8a682-2f02-477b-a4dd-bc5107be51a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import * \n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7dacc4e3-ae90-4545-b63a-89f20dcfd691",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#read from bronze delta table\n",
    "df = spark.read.table('bronze.orders')\n",
    "\n",
    "#type casting\n",
    "df.withColumn('order_id' ,col('order_id').cast('int'))\n",
    "\n",
    "#rename column\n",
    "df.withColumnRenamed('timestamp_ts' , 'current_timestamp_new')\n",
    "\n",
    "# Filtering invalid records (business rules)\n",
    "df.filter(col('age') > 18, col('amount') >= 0)\n",
    "\n",
    "\n",
    "#Deduplication (window or dropDuplicates)\n",
    "df.dropDuplicates(['order_id'])\n",
    "\n",
    "\n",
    "#Flatten nested structures (if JSON assumed)\n",
    "df.withColumn('nested_col',\n",
    "    from_json(col('nested_struct'), nested_struct_schema)\n",
    ")\n",
    "df.withColumn('order_id' , col('nested_col.order_id'))\\\n",
    "    .withColumn('order_qty ', col('nested_col.order_qty'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#join , using inner to know only matching and not used broadcast since both are big tables and not fit in a single memory amd it will overwhelm\n",
    "spark.sql(\n",
    "    '''\n",
    "    select o.order_id , c.customer_id , o.order_qty as order_qty\n",
    "    from orders o\n",
    "    inner join customers c on o.customer_id = c.customer_id\n",
    "    group by c.customer_id, o.order_id \n",
    "    order by order_qty desc limit 5\n",
    "\n",
    "    '''\n",
    ")\n",
    "\n",
    "\n",
    "# write to silver  , append because i want to upsert new data to it , rather than over writng and save computation cost and no partition since i dont know exactly ehat is high cardinality or most used without it it will be mess so havent partioned\n",
    "\n",
    "df.write.format('delta')\\\n",
    "    .mode('append')\\\n",
    "    .save('/FileStore/tables/silver/orders')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8dec3dbc-cc27-426f-85a7-025fb6e3c122",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "GOLD LAYER â€” Analytics-ready (SQL)\n",
    "Here you switch to Spark SQL ðŸ‘Œ\n",
    "This is a good signal in interviews.\n",
    "What I want you to write and share:\n",
    "1. Create Gold table / view using SQL\n",
    "Include:\n",
    "Aggregations (GROUP BY)\n",
    "Joins\n",
    "Business metrics\n",
    "Examples:\n",
    "total_orders per customer\n",
    "total_revenue per day\n",
    "top customers by spend\n",
    "running totals or rank (window function)\n",
    "2. Explain why SQL here\n",
    "Fail-fast\n",
    "Easier debugging\n",
    "Analytics consumption\n",
    "ðŸ‘‰ This proves you understand layer intent, not just syntax.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f39af225-45ea-4eaf-a6a2-591c0fa055dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    " -- Aggregations (GROUP BY)\n",
    "\n",
    "select order_id, count(*) as total_orders\n",
    "from orders\n",
    "group by order_id;\n",
    " \n",
    "\n",
    "--Joins\n",
    "\n",
    "select o.order_id , c.customer_id , o.order_qty as order_qty\n",
    "from orders o\n",
    "inner join customers c on o.customer_id = c.customer_id\n",
    "group by c.customer_id, o.order_id \n",
    "order by order_qty desc limit 5\n",
    "\n",
    "\n",
    "--Business metrics\n",
    "--total_orders per customer\n",
    "\n",
    "select c.customer_id, count(o.order_id) as total_orders\n",
    "from orders o\n",
    "inner join customers c on o.customer_id = c.customer_id\n",
    "group by c.customer_id\n",
    "order by total_orders desc\n",
    "\n",
    "--#* total_revenue per day\n",
    "select o.order_date , sum(o.order_qty * o.unit_price) as revenue \n",
    "from orders o\n",
    "inner join customers c on o.customer_id = c.customer_id\n",
    "group by o.order_date\n",
    "order by revenue desc\n",
    "\n",
    "--#* top customers by spend\n",
    "select c.customer_id, sum(o.order_qty * o.unit_price) as total_spend\n",
    "from orders o\n",
    "inner join customers c on o.customer_id = c.customer_id\n",
    "group by c.customer_id\n",
    "order by total_spend desc\n",
    "limit 10\n",
    "\n",
    "\n",
    "--#* running totals\n",
    "\n",
    "select customer_id , order_date , amount , sum(amount)\n",
    "over (partition by customer_id order by amount rows between unbounded preceding and current row) as cum_sum\n",
    "from master_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3633c87c-4f8b-40ae-9aff-bdc54b9b4a28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "test trail",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
